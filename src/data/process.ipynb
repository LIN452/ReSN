{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse, stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset_new(dataset_name:str = 'amazon-book',group_num:int = 5,threshold: int = 1) -> Tuple:\n",
    "    \"\"\"Load and Preprocess datasets.\"\"\"\n",
    "    # load dataset.\n",
    "    path = Path(f'../../data/{dataset_name}')\n",
    "    train_file = str(path/'train.txt')\n",
    "    test_file = str(path/'test.txt')\n",
    "\n",
    "    num_items = 0\n",
    "    num_users = 0\n",
    "    n_train = 0\n",
    "   \n",
    "    with open(train_file) as f:\n",
    "        for l in f.readlines():\n",
    "            if len(l) >0:\n",
    "                l = l.strip('\\n').split(' ')\n",
    "                items = [int(i) for i in l[1:]]\n",
    "                uid = int(l[0])\n",
    "                num_users = max(num_users,uid)\n",
    "                if items != []:\n",
    "                    num_items = max(num_items,max(items))\n",
    "                n_train += len(items)\n",
    "    \n",
    "    with open(test_file) as f:\n",
    "        for l in f.readlines():\n",
    "            if len(l) >0:\n",
    "                l = l.strip('\\n')\n",
    "                try:\n",
    "                    items = [int(i) for i in l.split(' ')[1:]]\n",
    "                except Exception:\n",
    "                    continue\n",
    "                uid = int(l[0])\n",
    "                if len(items)>0:\n",
    "                    num_items = max(num_items,max(items))\n",
    "                num_users = max(num_users,uid)\n",
    "                \n",
    "\n",
    "    num_items = num_items+1\n",
    "    num_users = num_users+1\n",
    "\n",
    "    print(num_items)\n",
    "    print(num_users)\n",
    "\n",
    "    train = np.zeros((n_train,2))\n",
    "    idx = 0 \n",
    "    item_freq = np.zeros(num_items)\n",
    "    user_freq = np.zeros(num_users)\n",
    "    \n",
    "    target_u = [[] for i in range(num_users)] \n",
    "    target_u_pop = [[[]for j in range(group_num)]for i in range(num_users)]\n",
    "    candidate_u =[[] for i in range(num_users)]\n",
    "    pos_u =[[] for i in range(num_users)]\n",
    "    group_item = [[]for i in range(group_num)]\n",
    "    all =set(list(range(num_items)))\n",
    "\n",
    "\n",
    "    with open(train_file) as f:\n",
    "        for l in f.readlines():\n",
    "            if len(l) >0:\n",
    "                l = l.strip('\\n').split(' ')\n",
    "                items = [int(i) for i in l[1:]]\n",
    "                uid = int(l[0])\n",
    "                num = len(items)\n",
    "                user_freq[uid]+=num\n",
    "                pos_u[uid] = items\n",
    "                candidate_u[uid] = list(all - set(items))\n",
    "                for i in range(num):\n",
    "                    train[idx+i,0] = uid\n",
    "                    train[idx+i,1] = items[i]\n",
    "                    item_freq[items[i]] = item_freq[items[i]]+1       \n",
    "                idx += num\n",
    "    '''\n",
    "    all_data = pd.DataFrame(\n",
    "        np.zeros((num_users, num_items))).stack().reset_index()\n",
    "    all_data = all_data.values[:, :2]\n",
    "    #print(all_data.shape)\n",
    "    \n",
    "    unlabeled_data = np.array(\n",
    "        list(set(map(tuple, all_data)) - set(map(tuple, train))), dtype=int)\n",
    "    train = np.r_[np.c_[train, np.ones(train.shape[0])],\n",
    "                  np.c_[unlabeled_data, np.zeros(unlabeled_data.shape[0])]]\n",
    "    '''\n",
    "    print('train shape')\n",
    "    print(train.shape)\n",
    "    \n",
    "    # save datasets\n",
    "    path = Path(f'../../data/{dataset_name}/point')\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    path2 = Path(f'../../data/{dataset_name}/point/5')\n",
    "    path2.mkdir(parents=True, exist_ok=True)\n",
    "    np.save(str(path / 'train.npy'), arr=train.astype(np.int))\n",
    "    np.save(str(path / 'item_freq.npy'), arr=item_freq)\n",
    "    np.save(str(path / 'user_freq.npy'), arr=user_freq)\n",
    "    \n",
    "    #group_num=5\n",
    "    ###############group devided#########################\n",
    "    #group_mask = np.zeros((num_items,group_num))\n",
    "    item_idx = item_freq.argsort()\n",
    "    tot_pop = np.sum(item_freq)\n",
    "    average_pop = tot_pop / group_num\n",
    "    j = 0\n",
    "    for i in range(group_num):\n",
    "        cur_pop = 0\n",
    "        while (cur_pop < average_pop) and (j<num_items):\n",
    "            term_idx = item_idx[j]\n",
    "            group_item[i].append(term_idx)\n",
    "            j = j+1\n",
    "            cur_pop = cur_pop +item_freq[term_idx]\n",
    "    print('group done!')\n",
    "   \n",
    "############################################################\n",
    "    \n",
    "    with open(test_file) as f:\n",
    "        for l in f.readlines():\n",
    "            if len(l) >0:\n",
    "                l = l.strip('\\n')\n",
    "                try:\n",
    "                    items = [int(i) for i in l.split(' ')]\n",
    "                except Exception:\n",
    "                    continue\n",
    "                uid = items[0]\n",
    "                items = items[1:]\n",
    "                #print(uid)\n",
    "                target_u[uid] = items\n",
    "                for k in range (group_num):\n",
    "                    target_u_pop[uid][k]= list(set(items) & set(group_item[k])) \n",
    "            else:\n",
    "                 break\n",
    "    def cmp_by_item_freq(a,b):\n",
    "            if(item_freq[a]>item_freq[b]):\n",
    "                return -1\n",
    "            elif(item_freq[a]<item_freq[b]):\n",
    "                return 1\n",
    "            else :\n",
    "                return 0\n",
    "\n",
    "    for u in range(num_users):\n",
    "        target_u[u]= sorted(target_u[u],key = functools.cmp_to_key(cmp_by_item_freq))\n",
    "    \n",
    "    np.save(str(path/str(group_num)/'group_item.npy'),arr=np.array(group_item))\n",
    "    np.save(str(path/str(group_num)/'target_u.npy'),arr=np.array(target_u))\n",
    "    np.save(str(path/str(group_num)/'target_u_pop.npy'),arr=np.array(target_u_pop))\n",
    "    np.save(str(path/str(group_num)/'candidate_u.npy'),arr=np.array(candidate_u))\n",
    "    np.save(str(path/str(group_num)/'pos_u.npy'),arr=np.array(pos_u))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13096\n",
      "160377\n",
      "train shape\n",
      "(2024510, 2)\n",
      "group done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-5ed66c9c3105>:140: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np.save(str(path/str(group_num)/'group_item.npy'),arr=np.array(group_item))\n",
      "<ipython-input-4-5ed66c9c3105>:141: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np.save(str(path/str(group_num)/'target_u.npy'),arr=np.array(target_u))\n",
      "<ipython-input-4-5ed66c9c3105>:142: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np.save(str(path/str(group_num)/'target_u_pop.npy'),arr=np.array(target_u_pop))\n",
      "<ipython-input-4-5ed66c9c3105>:143: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np.save(str(path/str(group_num)/'candidate_u.npy'),arr=np.array(candidate_u))\n",
      "<ipython-input-4-5ed66c9c3105>:144: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np.save(str(path/str(group_num)/'pos_u.npy'),arr=np.array(pos_u))\n"
     ]
    }
   ],
   "source": [
    "preprocess_dataset_new(dataset_name='ml-1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
