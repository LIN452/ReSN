{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_name = 'ml-1m'\n",
    "\n",
    "target_u = np.load(f'../../data/{dataset_name}/point/5/target_u.npy',allow_pickle=True).tolist()\n",
    "pos_u = np.load(f'../../data/{dataset_name}/point/5/pos_u.npy',allow_pickle=True).tolist()\n",
    "group_item = np.load(f'../../data/{dataset_name}/point/5/group_item.npy',allow_pickle=True).tolist()\n",
    "num_user = len(target_u)\n",
    "\n",
    "print(num_user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_item = max([max(it) for it in group_item]) +1\n",
    "\n",
    "pos_i = [ [] for i in range(num_item)]\n",
    "target_i = [[] for i in range(num_item)]\n",
    "\n",
    "test_user = [[] for i in range(num_user)]\n",
    "train_user = pos_u\n",
    "\n",
    "print(num_item)\n",
    "\n",
    "sum_iter = sum([len(x) for x in target_u])\n",
    "aver_iter = sum_iter//num_item\n",
    "print(aver_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in range(num_user):\n",
    "    for item in target_u[u]:\n",
    "        target_i[item].append(u)\n",
    "    for item in pos_u[u]:\n",
    "        pos_i[item].append(u)\n",
    "\n",
    "for item in range(num_item):\n",
    "    if aver_iter <= len(target_i[item]):     \n",
    "        test_tmp = np.random.choice(target_i[item],size =aver_iter,replace=False)\n",
    "        for u in target_i[item]:\n",
    "            if u not in test_tmp:\n",
    "                train_user[u].append(item)\n",
    "            else:\n",
    "                test_user[u].append(item)\n",
    "    else :\n",
    "        for u in target_i[item]:\n",
    "            test_user[u].append(item)\n",
    "        left = min(aver_iter - len(target_i[item]),len(pos_i[item]))\n",
    "        extra_user =  np.random.choice(pos_i[item],size =left,replace=False)\n",
    "        for u in extra_user:\n",
    "            test_user[u].append(item)\n",
    "            train_user[u].remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../../data/{dataset_name}_unbiased/test.txt' , 'w') as f:\n",
    "    file = ''\n",
    "    for user, items in enumerate(test_user):\n",
    "        file += str(user) + ' '\n",
    "        for item in items:\n",
    "            file += str(item) + ' '\n",
    "        file = file.strip(' ')\n",
    "        file += '\\n'\n",
    "    f.write(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../../data/{dataset_name}_unbiased/train.txt' , 'w') as f:\n",
    "    file = ''\n",
    "    for user, items in enumerate(train_user):\n",
    "        file += str(user) + ' '\n",
    "        for item in items:\n",
    "            file += str(item) + ' '\n",
    "        file = file.strip(' ')\n",
    "        file += '\\n'\n",
    "    f.write(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
